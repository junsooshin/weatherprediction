{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Max Temperature using Machine Learning\n",
    "*Junsoo Derek Shin*\n",
    "<br>\n",
    "*May 2018*\n",
    "***\n",
    "### Purpose\n",
    "The purpose of the project is to predict max temperatures of the days in April 2018 using machine learning techniques.\n",
    "\n",
    "The general guide on the machine learning concepts and the inspiration to apply them came from came from these two sources:\n",
    "1. https://www.kaggle.com/learn/machine-learning\n",
    "2. http://stackabuse.com/using-machine-learning-to-predict-the-weather-part-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get and Load Weather Underground Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`extract_weather_data()`** function asks the Weather Underground API for the historic data and writes the returned JSON data into a text file. The delay is put in, so that the number of requests doesn't exceed the 10-requests-per-minute limit. There is also daily limit of 500 requests, so `days` argument should not be greater than 500. I have already run this function and gathered data from January 1, 2014 to April 30, 2018, and the data is available in the `weatherdata.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "\n",
    "from collections import namedtuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get history JSON data from the Weather Underground API\n",
    "# def extract_weather_data(api_key, base_url, target_date, days):\n",
    "#     with open('weatherdata.txt', 'a') as outfile:\n",
    "#         for _ in range(days):\n",
    "#             request = base_url.format(api_key, target_date.strftime('%Y%m%d'))\n",
    "#             response = requests.get(request)\n",
    "#             if response.status_code == 200:\n",
    "#                 data = response.json()[\"history\"][\"dailysummary\"][0]\n",
    "#                 json.dump(data, outfile)\n",
    "#                 outfile.write('\\n')\n",
    "#             time.sleep(6)\n",
    "#             target_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fill_dateframe()`** function reads the text file filled with JSON objects and creates a Pandas DataFrame from it. The `target_date` argument is the starting date of this weather text file and should be a `datetime` object like `datetime(2014, 1, 1)`. This date increments as we create the DataFrame and works as the index. The `namedtuple` is similar to a struct or class and lets us use attributes, so that the code is more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from the text file of JSON objects, create a list of namedtuples, and use it\n",
    "# to create a DataFrame\n",
    "def fill_dataframe(target_date):\n",
    "    features = [\"date\", \"meantempm\", \"meandewptm\", \"meanpressurem\", \n",
    "                \"maxhumidity\", \"minhumidity\", \"maxtempm\", \"mintempm\", \n",
    "                \"maxdewptm\", \"mindewptm\", \"maxpressurem\", \"minpressurem\", \n",
    "                \"precipm\"]\n",
    "    DailySummary = namedtuple(\"DailySummary\", features)\n",
    "    records = []\n",
    "    with open('weatherdata.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            records.append(DailySummary(\n",
    "                date = target_date,\n",
    "                meantempm = data[\"meantempm\"],\n",
    "                meandewptm = data[\"meandewptm\"],\n",
    "                meanpressurem = data[\"meanpressurem\"],\n",
    "                maxhumidity = data[\"maxhumidity\"],\n",
    "                minhumidity = data[\"minhumidity\"],\n",
    "                maxtempm = data[\"maxtempm\"],\n",
    "                mintempm = data[\"mintempm\"],\n",
    "                maxdewptm = data[\"maxdewptm\"],\n",
    "                mindewptm = data[\"mindewptm\"],\n",
    "                maxpressurem = data[\"maxpressurem\"],\n",
    "                minpressurem = data[\"minpressurem\"],\n",
    "                precipm = data[\"precipm\"],\n",
    "            ))\n",
    "            target_date += timedelta(days=1)\n",
    "    df = pd.DataFrame(records, columns=features).set_index('date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_date = datetime(2014, 1, 1)\n",
    "days = 365\n",
    "# extract_weather_data(API_KEY, BASE_URL, target_date, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = fill_dataframe(target_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns are `object` (or `string`). Let's convert them into numeric data, so that it's easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meantempm        object\n",
       "meandewptm       object\n",
       "meanpressurem    object\n",
       "maxhumidity      object\n",
       "minhumidity      object\n",
       "maxtempm         object\n",
       "mintempm         object\n",
       "maxdewptm        object\n",
       "mindewptm        object\n",
       "maxpressurem     object\n",
       "minpressurem     object\n",
       "precipm          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meantempm          int64\n",
       "meandewptm         int64\n",
       "meanpressurem    float64\n",
       "maxhumidity        int64\n",
       "minhumidity        int64\n",
       "maxtempm           int64\n",
       "mintempm           int64\n",
       "maxdewptm          int64\n",
       "mindewptm          int64\n",
       "maxpressurem       int64\n",
       "minpressurem       int64\n",
       "precipm           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.00', '9.65', '4.83', '1.02', '8.13', 'T', '0.51', '13.72',\n",
       "       '20.07', '0.76', '2.79', '0.25', '4.32', '28.19', '25.40', '7.87',\n",
       "       '8.38', '5.59', '6.35', '2.03', '7.37', '24.64', '56.64', '11.18',\n",
       "       '6.60', '5.84', '17.02', '15.75', '9.14', '1.27', '5.08', '3.81',\n",
       "       '8.89', '8.64', '1.52', '16.51', '4.57', '12.19', '3.56', '19.81',\n",
       "       '21.59', '7.11', '47.75', '26.92', '3.30', '29.46', '4.06',\n",
       "       '16.00', '22.10', '57.15', '14.99', '41.66', '36.58', '2.54',\n",
       "       '27.69', '73.66', '10.92', '14.22', '14.48', '3.05', '18.03',\n",
       "       '24.13', '2.29', '1.78', '9.40', '22.35', '9.91', '20.32', '6.86',\n",
       "       '5.33', '15.49', '23.11', '18.80', '10.16', '43.69', '36.32',\n",
       "       '12.70', '28.45', '12.45', '21.08', '16.76', '62.48', '18.54',\n",
       "       '21.84', '7.62', '10.67', '13.97', '19.30', '6.10', '25.91',\n",
       "       '35.05', '30.99', '24.38', '20.57', '28.96', '10.41', '26.16',\n",
       "       '28.70', '22.61', '46.74', '25.15', '13.46', '11.94', '19.56',\n",
       "       '41.15', '18.29', '39.62', '17.27', '34.54', '12.95', '16.26',\n",
       "       '54.10', '33.78', '35.81', '15.24', '39.37', '32.77', '23.88',\n",
       "       '11.68', '14.73', '34.29', '31.50', '32.00', '17.53', '29.72',\n",
       "       '29.21', '0.0', '2.3', '39.88', '5.6'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['precipm'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`precipm` column was the only column that couldn't be converted into numbers, and the reason was that it had values such as `'T'`, which stands for \"Trace\" or a very litte amount of precipitation. Since \"Trace\" should be different from zero precipitation, I will assign an arbitrary value of 0.01 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "trace_rows = data['precipm'].isnull()\n",
    "data.loc[trace_rows, 'precipm'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meantempm          int64\n",
       "meandewptm         int64\n",
       "meanpressurem    float64\n",
       "maxhumidity        int64\n",
       "minhumidity        int64\n",
       "maxtempm           int64\n",
       "mintempm           int64\n",
       "maxdewptm          int64\n",
       "mindewptm          int64\n",
       "maxpressurem       int64\n",
       "minpressurem       int64\n",
       "precipm          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 9.650e+00, 4.830e+00, 1.020e+00, 8.130e+00, 1.000e-02,\n",
       "       5.100e-01, 1.372e+01, 2.007e+01, 7.600e-01, 2.790e+00, 2.500e-01,\n",
       "       4.320e+00, 2.819e+01, 2.540e+01, 7.870e+00, 8.380e+00, 5.590e+00,\n",
       "       6.350e+00, 2.030e+00, 7.370e+00, 2.464e+01, 5.664e+01, 1.118e+01,\n",
       "       6.600e+00, 5.840e+00, 1.702e+01, 1.575e+01, 9.140e+00, 1.270e+00,\n",
       "       5.080e+00, 3.810e+00, 8.890e+00, 8.640e+00, 1.520e+00, 1.651e+01,\n",
       "       4.570e+00, 1.219e+01, 3.560e+00, 1.981e+01, 2.159e+01, 7.110e+00,\n",
       "       4.775e+01, 2.692e+01, 3.300e+00, 2.946e+01, 4.060e+00, 1.600e+01,\n",
       "       2.210e+01, 5.715e+01, 1.499e+01, 4.166e+01, 3.658e+01, 2.540e+00,\n",
       "       2.769e+01, 7.366e+01, 1.092e+01, 1.422e+01, 1.448e+01, 3.050e+00,\n",
       "       1.803e+01, 2.413e+01, 2.290e+00, 1.780e+00, 9.400e+00, 2.235e+01,\n",
       "       9.910e+00, 2.032e+01, 6.860e+00, 5.330e+00, 1.549e+01, 2.311e+01,\n",
       "       1.880e+01, 1.016e+01, 4.369e+01, 3.632e+01, 1.270e+01, 2.845e+01,\n",
       "       1.245e+01, 2.108e+01, 1.676e+01, 6.248e+01, 1.854e+01, 2.184e+01,\n",
       "       7.620e+00, 1.067e+01, 1.397e+01, 1.930e+01, 6.100e+00, 2.591e+01,\n",
       "       3.505e+01, 3.099e+01, 2.438e+01, 2.057e+01, 2.896e+01, 1.041e+01,\n",
       "       2.616e+01, 2.870e+01, 2.261e+01, 4.674e+01, 2.515e+01, 1.346e+01,\n",
       "       1.194e+01, 1.956e+01, 4.115e+01, 1.829e+01, 3.962e+01, 1.727e+01,\n",
       "       3.454e+01, 1.295e+01, 1.626e+01, 5.410e+01, 3.378e+01, 3.581e+01,\n",
       "       1.524e+01, 3.937e+01, 3.277e+01, 2.388e+01, 1.168e+01, 1.473e+01,\n",
       "       3.429e+01, 3.150e+01, 3.200e+01, 1.753e+01, 2.972e+01, 2.921e+01,\n",
       "       2.300e+00, 3.988e+01, 5.600e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['precipm'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Features/Columns\n",
    "What we want to predict is clear: it's `maxtempm`. However, we cannot use the data from the same date to train our model because we won't have those data from that day. So, one way to go about this is adding columns of measurements from the previous days. For example, for `meanpressurem`, we would have columns, such as `meanpressurem_1`, `meanpressurem_2`, `meanpressurem_3`, which are measurements from 1, 2 and 3 days prior.\n",
    "\n",
    "So let's add the columns for 1, 2 and 3-days-prior measurements for every column except for the temperature columns. For the first few rows at the top, we need a buffer because we don't have the prior-days data for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a feature and the number of prior days, add column(s) to the DataFrame\n",
    "def derive_nth_day_feature(df, feature, N):\n",
    "    num_rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i] for i in range(0, num_rows-N)]\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    for N in range(1, 4):\n",
    "        derive_nth_day_feature(data, feature, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meantempm', 'meandewptm', 'meanpressurem', 'maxhumidity',\n",
       "       'minhumidity', 'maxtempm', 'mintempm', 'maxdewptm', 'mindewptm',\n",
       "       'maxpressurem', 'minpressurem', 'precipm', 'meantempm_1', 'meantempm_2',\n",
       "       'meantempm_3', 'meandewptm_1', 'meandewptm_2', 'meandewptm_3',\n",
       "       'meanpressurem_1', 'meanpressurem_2', 'meanpressurem_3',\n",
       "       'maxhumidity_1', 'maxhumidity_2', 'maxhumidity_3', 'minhumidity_1',\n",
       "       'minhumidity_2', 'minhumidity_3', 'maxtempm_1', 'maxtempm_2',\n",
       "       'maxtempm_3', 'mintempm_1', 'mintempm_2', 'mintempm_3', 'maxdewptm_1',\n",
       "       'maxdewptm_2', 'maxdewptm_3', 'mindewptm_1', 'mindewptm_2',\n",
       "       'mindewptm_3', 'maxpressurem_1', 'maxpressurem_2', 'maxpressurem_3',\n",
       "       'minpressurem_1', 'minpressurem_2', 'minpressurem_3', 'precipm_1',\n",
       "       'precipm_2', 'precipm_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the measurements on the same day as the temperatures because we won't have them for the days we are trying to predict. If we can have those measurements, we can probably have temperatures for those days as well. So let's drop those columns.\n",
    "\n",
    "We also see that the columns are missing certain amount of values because of the missing n_day prior values. Other than those rows, everything seems to be filled in. Although every row is valuable, I don't want to impute values that could be way off, let's drop those 1-to-3 rows and obtain non-null data all around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['meandewptm', 'maxdewptm', 'mindewptm',\n",
    "                    'meanpressurem', 'maxpressurem', 'minpressurem',\n",
    "                    'maxhumidity', 'minhumidity',\n",
    "                    'precipm']\n",
    "data.drop(features_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1581 entries, 2014-01-01 to 2018-04-30\n",
      "Freq: D\n",
      "Data columns (total 39 columns):\n",
      "meantempm          1581 non-null int64\n",
      "maxtempm           1581 non-null int64\n",
      "mintempm           1581 non-null int64\n",
      "meantempm_1        1580 non-null float64\n",
      "meantempm_2        1579 non-null float64\n",
      "meantempm_3        1578 non-null float64\n",
      "meandewptm_1       1580 non-null float64\n",
      "meandewptm_2       1579 non-null float64\n",
      "meandewptm_3       1578 non-null float64\n",
      "meanpressurem_1    1580 non-null float64\n",
      "meanpressurem_2    1579 non-null float64\n",
      "meanpressurem_3    1578 non-null float64\n",
      "maxhumidity_1      1580 non-null float64\n",
      "maxhumidity_2      1579 non-null float64\n",
      "maxhumidity_3      1578 non-null float64\n",
      "minhumidity_1      1580 non-null float64\n",
      "minhumidity_2      1579 non-null float64\n",
      "minhumidity_3      1578 non-null float64\n",
      "maxtempm_1         1580 non-null float64\n",
      "maxtempm_2         1579 non-null float64\n",
      "maxtempm_3         1578 non-null float64\n",
      "mintempm_1         1580 non-null float64\n",
      "mintempm_2         1579 non-null float64\n",
      "mintempm_3         1578 non-null float64\n",
      "maxdewptm_1        1580 non-null float64\n",
      "maxdewptm_2        1579 non-null float64\n",
      "maxdewptm_3        1578 non-null float64\n",
      "mindewptm_1        1580 non-null float64\n",
      "mindewptm_2        1579 non-null float64\n",
      "mindewptm_3        1578 non-null float64\n",
      "maxpressurem_1     1580 non-null float64\n",
      "maxpressurem_2     1579 non-null float64\n",
      "maxpressurem_3     1578 non-null float64\n",
      "minpressurem_1     1580 non-null float64\n",
      "minpressurem_2     1579 non-null float64\n",
      "minpressurem_3     1578 non-null float64\n",
      "precipm_1          1580 non-null float64\n",
      "precipm_2          1579 non-null float64\n",
      "precipm_3          1578 non-null float64\n",
      "dtypes: float64(36), int64(3)\n",
      "memory usage: 574.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1578 entries, 2014-01-04 to 2018-04-30\n",
      "Freq: D\n",
      "Data columns (total 39 columns):\n",
      "meantempm          1578 non-null int64\n",
      "maxtempm           1578 non-null int64\n",
      "mintempm           1578 non-null int64\n",
      "meantempm_1        1578 non-null float64\n",
      "meantempm_2        1578 non-null float64\n",
      "meantempm_3        1578 non-null float64\n",
      "meandewptm_1       1578 non-null float64\n",
      "meandewptm_2       1578 non-null float64\n",
      "meandewptm_3       1578 non-null float64\n",
      "meanpressurem_1    1578 non-null float64\n",
      "meanpressurem_2    1578 non-null float64\n",
      "meanpressurem_3    1578 non-null float64\n",
      "maxhumidity_1      1578 non-null float64\n",
      "maxhumidity_2      1578 non-null float64\n",
      "maxhumidity_3      1578 non-null float64\n",
      "minhumidity_1      1578 non-null float64\n",
      "minhumidity_2      1578 non-null float64\n",
      "minhumidity_3      1578 non-null float64\n",
      "maxtempm_1         1578 non-null float64\n",
      "maxtempm_2         1578 non-null float64\n",
      "maxtempm_3         1578 non-null float64\n",
      "mintempm_1         1578 non-null float64\n",
      "mintempm_2         1578 non-null float64\n",
      "mintempm_3         1578 non-null float64\n",
      "maxdewptm_1        1578 non-null float64\n",
      "maxdewptm_2        1578 non-null float64\n",
      "maxdewptm_3        1578 non-null float64\n",
      "mindewptm_1        1578 non-null float64\n",
      "mindewptm_2        1578 non-null float64\n",
      "mindewptm_3        1578 non-null float64\n",
      "maxpressurem_1     1578 non-null float64\n",
      "maxpressurem_2     1578 non-null float64\n",
      "maxpressurem_3     1578 non-null float64\n",
      "minpressurem_1     1578 non-null float64\n",
      "minpressurem_2     1578 non-null float64\n",
      "minpressurem_3     1578 non-null float64\n",
      "precipm_1          1578 non-null float64\n",
      "precipm_2          1578 non-null float64\n",
      "precipm_3          1578 non-null float64\n",
      "dtypes: float64(36), int64(3)\n",
      "memory usage: 493.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into **`train_data`** and **`april_data`**, so that we can train our models with **`train_data`** and eventually test them with **`april_data`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 30 entries, 2018-04-01 to 2018-04-30\n",
      "Freq: D\n",
      "Data columns (total 39 columns):\n",
      "meantempm          30 non-null int64\n",
      "maxtempm           30 non-null int64\n",
      "mintempm           30 non-null int64\n",
      "meantempm_1        30 non-null float64\n",
      "meantempm_2        30 non-null float64\n",
      "meantempm_3        30 non-null float64\n",
      "meandewptm_1       30 non-null float64\n",
      "meandewptm_2       30 non-null float64\n",
      "meandewptm_3       30 non-null float64\n",
      "meanpressurem_1    30 non-null float64\n",
      "meanpressurem_2    30 non-null float64\n",
      "meanpressurem_3    30 non-null float64\n",
      "maxhumidity_1      30 non-null float64\n",
      "maxhumidity_2      30 non-null float64\n",
      "maxhumidity_3      30 non-null float64\n",
      "minhumidity_1      30 non-null float64\n",
      "minhumidity_2      30 non-null float64\n",
      "minhumidity_3      30 non-null float64\n",
      "maxtempm_1         30 non-null float64\n",
      "maxtempm_2         30 non-null float64\n",
      "maxtempm_3         30 non-null float64\n",
      "mintempm_1         30 non-null float64\n",
      "mintempm_2         30 non-null float64\n",
      "mintempm_3         30 non-null float64\n",
      "maxdewptm_1        30 non-null float64\n",
      "maxdewptm_2        30 non-null float64\n",
      "maxdewptm_3        30 non-null float64\n",
      "mindewptm_1        30 non-null float64\n",
      "mindewptm_2        30 non-null float64\n",
      "mindewptm_3        30 non-null float64\n",
      "maxpressurem_1     30 non-null float64\n",
      "maxpressurem_2     30 non-null float64\n",
      "maxpressurem_3     30 non-null float64\n",
      "minpressurem_1     30 non-null float64\n",
      "minpressurem_2     30 non-null float64\n",
      "minpressurem_3     30 non-null float64\n",
      "precipm_1          30 non-null float64\n",
      "precipm_2          30 non-null float64\n",
      "precipm_3          30 non-null float64\n",
      "dtypes: float64(36), int64(3)\n",
      "memory usage: 9.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1548 entries, 2014-01-04 to 2018-03-31\n",
      "Freq: D\n",
      "Data columns (total 39 columns):\n",
      "meantempm          1548 non-null int64\n",
      "maxtempm           1548 non-null int64\n",
      "mintempm           1548 non-null int64\n",
      "meantempm_1        1548 non-null float64\n",
      "meantempm_2        1548 non-null float64\n",
      "meantempm_3        1548 non-null float64\n",
      "meandewptm_1       1548 non-null float64\n",
      "meandewptm_2       1548 non-null float64\n",
      "meandewptm_3       1548 non-null float64\n",
      "meanpressurem_1    1548 non-null float64\n",
      "meanpressurem_2    1548 non-null float64\n",
      "meanpressurem_3    1548 non-null float64\n",
      "maxhumidity_1      1548 non-null float64\n",
      "maxhumidity_2      1548 non-null float64\n",
      "maxhumidity_3      1548 non-null float64\n",
      "minhumidity_1      1548 non-null float64\n",
      "minhumidity_2      1548 non-null float64\n",
      "minhumidity_3      1548 non-null float64\n",
      "maxtempm_1         1548 non-null float64\n",
      "maxtempm_2         1548 non-null float64\n",
      "maxtempm_3         1548 non-null float64\n",
      "mintempm_1         1548 non-null float64\n",
      "mintempm_2         1548 non-null float64\n",
      "mintempm_3         1548 non-null float64\n",
      "maxdewptm_1        1548 non-null float64\n",
      "maxdewptm_2        1548 non-null float64\n",
      "maxdewptm_3        1548 non-null float64\n",
      "mindewptm_1        1548 non-null float64\n",
      "mindewptm_2        1548 non-null float64\n",
      "mindewptm_3        1548 non-null float64\n",
      "maxpressurem_1     1548 non-null float64\n",
      "maxpressurem_2     1548 non-null float64\n",
      "maxpressurem_3     1548 non-null float64\n",
      "minpressurem_1     1548 non-null float64\n",
      "minpressurem_2     1548 non-null float64\n",
      "minpressurem_3     1548 non-null float64\n",
      "precipm_1          1548 non-null float64\n",
      "precipm_2          1548 non-null float64\n",
      "precipm_3          1548 non-null float64\n",
      "dtypes: float64(36), int64(3)\n",
      "memory usage: 483.8 KB\n"
     ]
    }
   ],
   "source": [
    "april_data = data[data.index >= datetime(2018, 4, 1)]\n",
    "train_data = data.drop(april_data.index, axis=0)\n",
    "april_data.info()\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linear Regression\n",
    "Now we can build our first model using linear regression! Linear regression requires that the features we are using and the target variable we are trying to predict have linear relationships. One way to assess that is by calculating Pearson correlation coefficients. These values range from -1 to 1, and the values close to -1 and 1 mean that the features have strong linear relationships with the target variable, and values close to 0 mean that they have weak linear relationships with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxtempm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpressurem_1</th>\n",
       "      <td>-0.178263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_3</th>\n",
       "      <td>-0.155820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_2</th>\n",
       "      <td>-0.127825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_2</th>\n",
       "      <td>-0.093009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_1</th>\n",
       "      <td>-0.091274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_3</th>\n",
       "      <td>-0.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_1</th>\n",
       "      <td>-0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_3</th>\n",
       "      <td>-0.008143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_2</th>\n",
       "      <td>0.027470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_2</th>\n",
       "      <td>0.059617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_3</th>\n",
       "      <td>0.067705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_1</th>\n",
       "      <td>0.083426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_1</th>\n",
       "      <td>0.101271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_3</th>\n",
       "      <td>0.114744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_3</th>\n",
       "      <td>0.122197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_2</th>\n",
       "      <td>0.127215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_2</th>\n",
       "      <td>0.151321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_1</th>\n",
       "      <td>0.185425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_3</th>\n",
       "      <td>0.716142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_3</th>\n",
       "      <td>0.737143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_2</th>\n",
       "      <td>0.742264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_3</th>\n",
       "      <td>0.754770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_2</th>\n",
       "      <td>0.758649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_2</th>\n",
       "      <td>0.772432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_3</th>\n",
       "      <td>0.784337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_3</th>\n",
       "      <td>0.807438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_3</th>\n",
       "      <td>0.810972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_2</th>\n",
       "      <td>0.814671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_1</th>\n",
       "      <td>0.820686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_2</th>\n",
       "      <td>0.830728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_2</th>\n",
       "      <td>0.832894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_1</th>\n",
       "      <td>0.832950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_1</th>\n",
       "      <td>0.841940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_1</th>\n",
       "      <td>0.887950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_1</th>\n",
       "      <td>0.891138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_1</th>\n",
       "      <td>0.900831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm</th>\n",
       "      <td>0.946792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm</th>\n",
       "      <td>0.986688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 maxtempm\n",
       "maxpressurem_1  -0.178263\n",
       "maxpressurem_3  -0.155820\n",
       "maxpressurem_2  -0.127825\n",
       "precipm_2       -0.093009\n",
       "precipm_1       -0.091274\n",
       "precipm_3       -0.078400\n",
       "meanpressurem_1 -0.014725\n",
       "meanpressurem_3 -0.008143\n",
       "meanpressurem_2  0.027470\n",
       "minhumidity_2    0.059617\n",
       "minhumidity_3    0.067705\n",
       "minhumidity_1    0.083426\n",
       "minpressurem_1   0.101271\n",
       "minpressurem_3   0.114744\n",
       "maxhumidity_3    0.122197\n",
       "maxhumidity_2    0.127215\n",
       "minpressurem_2   0.151321\n",
       "maxhumidity_1    0.185425\n",
       "maxdewptm_3      0.716142\n",
       "meandewptm_3     0.737143\n",
       "maxdewptm_2      0.742264\n",
       "mindewptm_3      0.754770\n",
       "meandewptm_2     0.758649\n",
       "mindewptm_2      0.772432\n",
       "maxtempm_3       0.784337\n",
       "meantempm_3      0.807438\n",
       "mintempm_3       0.810972\n",
       "maxtempm_2       0.814671\n",
       "maxdewptm_1      0.820686\n",
       "mintempm_2       0.830728\n",
       "meantempm_2      0.832894\n",
       "meandewptm_1     0.832950\n",
       "mindewptm_1      0.841940\n",
       "mintempm_1       0.887950\n",
       "maxtempm_1       0.891138\n",
       "meantempm_1      0.900831\n",
       "mintempm         0.946792\n",
       "meantempm        0.986688\n",
       "maxtempm         1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()[['maxtempm']].sort_values('maxtempm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the features with temperature and dew point have linear relationships with max temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_features = [feature for feature in train_data.columns\n",
    "                                       if 'temp' in feature or\n",
    "                                          'dewpt' in feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model will use linear regression. It will train on 80% of the data and tested on the 20% of the data. Using cross validation, we will cut the data in five, rotate the training-testing-data pairs, and then calculate the mean of those five scores, which will be the final score for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4218877102056657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = train_data[linear_features].drop(['meantempm', 'maxtempm', 'mintempm'], axis=1)\n",
    "y = train_data['maxtempm']\n",
    "\n",
    "scores = -1 * cross_val_score(LinearRegression(),\n",
    "                              X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7816537467700257"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "prev_maxtemp = X['maxtempm_1']\n",
    "mean_absolute_error(y, prev_maxtemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the mean error from the linear regression model is slightly better than just using the max temperatures from a day before, the error of 3.42 degrees Celsius (6.16 degrees Fahrenheit) is pretty high. Let's see if we can improve our predictions with another technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision Tree, Random Forest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(['meantempm', 'maxtempm', 'mintempm'], axis=1)\n",
    "y = train_data['maxtempm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4.101516419277191\n",
      "50 4.0220876461116175\n",
      "500 4.929750328286971\n",
      "5000 4.934778160559557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    scores = -1 * cross_val_score(DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes),\n",
    "                            X, y,\n",
    "                            cv=5,\n",
    "                            scoring='neg_mean_absolute_error')\n",
    "    print(str(max_leaf_nodes), str(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.503876479799562"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "scores = -1 * cross_val_score(RandomForestRegressor(50),\n",
    "                              X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "scores = -1 * cross_val_score(XGBRegressor(n_estimators=1000, learning_rate=0.005),\n",
    "                              X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict April 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the models trained and tested on the 3 years of data, the linear regression model seems to be the most accurate model, so we will use the linear regression model to predict the daily maximum temperatures of April 2018. First, let's train the model using the entire 3 years of data (not just 80% of them) since the April data will be our test data anyway. Then using the April data, we will make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train_data['maxtempm']\n",
    "train_X = train_data[linear_features].drop(['meantempm', 'maxtempm', 'mintempm'], axis=1)\n",
    "test_y = april_data['maxtempm']\n",
    "test_X = april_data[linear_features].drop(['meantempm', 'maxtempm', 'mintempm'], axis=1)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(train_X, train_y)\n",
    "\n",
    "predictions = linear_model.predict(test_X)\n",
    "print(\"Linear Regression model's mean absolute error: \"+ str(mean_absolute_error(test_y, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two naive benchmarks. The first benchmark will use previous-day measurements as its predictions. The second benchmark will use previous-year measurements as its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_day_benchmark = april_data['maxtempm_1']\n",
    "prev_year_benchmark = train_data.loc[(train_data.index >= datetime(2017, 4, 1)) & \n",
    "                                     (train_data.index <= datetime(2017, 4, 30))]['maxtempm']\n",
    "print(\"prev_day MAE: \" + str(mean_absolute_error(test_y, prev_day_benchmark)))\n",
    "print(\"prev_year MAE: \" + str(mean_absolute_error(test_y, prev_year_benchmark)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "April 2018 was a tough month to predict maximum temperatures. Maximum temperatures seemed to have changed day-to-day, and they were even more different from those of April 2017. Both benchmarks and our linear regression model performed with, I would say, large errors. However, the linear regression model does do better than the naive benchmarks, so this is a decent start. After studying more about the machine learning algorithms, I want to figure out what made the algorithms I used here struggled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Attempt to Understand What Happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how my predictions and the actual maximum temperatures look on a scatterplot. If the predicitons were good, the plot would show a straight, diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(predictions, test_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot looks more like two diagonal lines, and really not a straight line that I wanted.\n",
    "\n",
    "Let's check if there were any outliers in my training data that I missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_used = [feature for feature in linear_features \n",
    "                                     if feature not in ['meantempm', 'maxtempm', 'mintempm']]\n",
    "for feature in features_used:\n",
    "    train_data[feature].hist()\n",
    "    plt.xlabel(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be many outliers in our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were the 2018 April really strange?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(test_y)\n",
    "plt.show()\n",
    "plt.plot(train_data[(train_data.index >= datetime(2017, 4, 1)) & (train_data.index <= datetime(2017, 4, 30))]['maxtempm'])\n",
    "plt.show()\n",
    "plt.plot(train_data[(train_data.index >= datetime(2016, 4, 1)) & (train_data.index <= datetime(2016, 4, 30))]['maxtempm'])\n",
    "plt.show()\n",
    "plt.plot(train_data[(train_data.index >= datetime(2015, 4, 1)) & (train_data.index <= datetime(2015, 4, 30))]['maxtempm'])\n",
    "plt.show()\n",
    "plt.plot(train_data[(train_data.index >= datetime(2014, 4, 1)) & (train_data.index <= datetime(2014, 4, 30))]['maxtempm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like it.\n",
    "\n",
    "It is true that using the temperature and dew point measurements in the 3 previous days to predict the maximum temperature for the next day seemed difficult even during the training of the model. Perhaps the model should have been more strongly fit (maybe it's underfit at the moment), or perhaps the model should have been trained on the April data only, or perhaps only the strongly-correlated variables should have been used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_preds = linear_model.predict(train_X)\n",
    "print(str(mean_absolute_error(train_y, my_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(my_preds, train_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training a linear regression model only on the past April data from 2014 to 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_april_train = train_data[train_data.index.month == 4]\n",
    "all_april_train_X = all_april_train[features_used]\n",
    "all_april_train_y = all_april_train['maxtempm']\n",
    "april_linear_regression_model = LinearRegression()\n",
    "april_linear_regression_model.fit(all_april_train_X, all_april_train_y)\n",
    "\n",
    "april_preds = april_linear_regression_model.predict(test_X)\n",
    "print(\"Linear Regression model's mean absolute error: \"+ str(mean_absolute_error(test_y, april_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only using the April data did worse than using the entire 4 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
